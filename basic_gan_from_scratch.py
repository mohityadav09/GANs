# -*- coding: utf-8 -*-
"""Basic GAN from scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13A4XgMKoFcAl7OhVrbhdJRwGHKatJWvB
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch

import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

from tqdm.notebook import tqdm
import albumentations as A

!pip install torch torchvision tensorboard

from torch.utils.tensorboard import SummaryWriter

DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

class Discriminator(nn.Module):
  def __init__(self,in_features):
    super().__init__()
    self.disc=nn.Sequential(
        nn.Linear(in_features,128),
        nn.LeakyReLU(0.1),
        nn.Linear(128,8),
        nn.LeakyReLU(0.1),
        nn.Linear(8,1),
        nn.Sigmoid(),
    )
  def forward(self,x):
    return self.disc(x)

class Generator(nn.Module):
  def __init__(self,latent_dim,img_dim):
    super().__init__()
    self.gen=nn.Sequential(
        nn.Linear(latent_dim,256),
        nn.LeakyReLU(0.1),

        nn.Linear(256,img_dim),
        nn.Tanh(),
    )
  def forward(self,x):
    return self.gen(x)

import torchvision.datasets as datasets
transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5),(0.5))])
mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
loader=DataLoader(mnist_trainset,batch_size=16,shuffle=True)

lr=3e-4
epochs=30
latent_dim=64
img_dim=28*28

data_gen=torch.randn((16,latent_dim)).to(DEVICE)
disc=Discriminator(img_dim).to(DEVICE)
gen=Generator(latent_dim,img_dim).to(DEVICE)

criterion=nn.BCELoss()
optimizer_disc=torch.optim.Adam(disc.parameters(),lr=lr)
optimizer_gen=torch.optim.Adam(gen.parameters(),lr=lr)
writer_fake = SummaryWriter(f"logs/fake")
writer_real = SummaryWriter(f"logs/real")
step = 0

import torchvision

for epoch in range(epochs):

  disc.train()
  gen.train()
  progress=tqdm(loader,total=len(loader))
  for i,(images,label) in enumerate(progress):

    img=images.view(-1,784).to(DEVICE)
    #train disc
    batch_size=images.shape[0]
    noise=torch.randn(batch_size,latent_dim).to(DEVICE)

    disc_real=disc(img).view(-1)
    loss_real=criterion(disc_real,torch.ones_like(disc_real))
    fake_img=gen(noise)


    disc_fake=disc(fake_img).view(-1)
    loss_fake=criterion(disc_fake,torch.zeros_like(disc_fake))
    loss_total=(loss_real+loss_fake)/2
    optimizer_disc.zero_grad()
    loss_total.backward(retain_graph=True)
    optimizer_disc.step()

    # train gen
    output=disc(fake_img)
    gen_loss=criterion(output,torch.ones_like(output))
    optimizer_gen.zero_grad()
    gen_loss.backward()
    optimizer_gen.step()

    if i == 0:
            print(
                f"Epoch [{epoch}/{epochs}] Batch {i}/{len(loader)} \
                      Loss D: {loss_total:.4f}, loss G: {gen_loss:.4f}"
            )

            with torch.no_grad():
                fake = gen(noise).reshape(-1, 1, 28, 28)
                data = images.reshape(-1, 1, 28, 28)
                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)
                img_grid_real = torchvision.utils.make_grid(data, normalize=True)

                writer_fake.add_image(
                    "Mnist Fake Images", img_grid_fake, global_step=step
                )
                writer_real.add_image(
                    "Mnist Real Images", img_grid_real, global_step=step
                )
                step += 1

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

torch.save(gen.state_dict(), 'gen_model_weights.pth')
torch.save(disc.state_dict(), 'disc_model_weights.pth')

